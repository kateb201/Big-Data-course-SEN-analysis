{"cells":[{"cell_type":"markdown","id":"qrC-AdUJEOAd","metadata":{"id":"qrC-AdUJEOAd"},"source":["# Consumer for Tweeter API "]},{"cell_type":"markdown","id":"mbhW3aIgEUHd","metadata":{"id":"mbhW3aIgEUHd"},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"id":"ee745982","metadata":{"id":"ee745982","outputId":"b86726ae-127a-48b7-fb88-b5b134c93656"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: vaderSentiment in /home/linuxu/anaconda3/lib/python3.8/site-packages (3.3.2)\n","Requirement already satisfied: requests in /home/linuxu/anaconda3/lib/python3.8/site-packages (from vaderSentiment) (2.27.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/linuxu/anaconda3/lib/python3.8/site-packages (from requests->vaderSentiment) (1.26.4)\n","Requirement already satisfied: idna<4,>=2.5 in /home/linuxu/anaconda3/lib/python3.8/site-packages (from requests->vaderSentiment) (2.10)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /home/linuxu/anaconda3/lib/python3.8/site-packages (from requests->vaderSentiment) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /home/linuxu/anaconda3/lib/python3.8/site-packages (from requests->vaderSentiment) (2020.12.5)\n","Requirement already satisfied: nltk in /home/linuxu/anaconda3/lib/python3.8/site-packages (3.6.1)\n","Requirement already satisfied: click in /home/linuxu/anaconda3/lib/python3.8/site-packages (from nltk) (7.1.2)\n","Requirement already satisfied: joblib in /home/linuxu/anaconda3/lib/python3.8/site-packages (from nltk) (1.0.1)\n","Requirement already satisfied: regex in /home/linuxu/anaconda3/lib/python3.8/site-packages (from nltk) (2021.4.4)\n","Requirement already satisfied: tqdm in /home/linuxu/anaconda3/lib/python3.8/site-packages (from nltk) (4.59.0)\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /home/linuxu/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["from confluent_kafka import Producer  \n","!pip install vaderSentiment\n","!pip install nltk\n","from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n","import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","import re\n","from pyspark.ml.classification import LogisticRegressionModel\n","import pandas as pd\n","from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n","from pyspark.sql import SQLContext\n","from pyspark.ml import Pipeline"]},{"cell_type":"markdown","id":"5oZ7I5hAEWge","metadata":{"id":"5oZ7I5hAEWge"},"source":["## Consumer Configuration"]},{"cell_type":"code","execution_count":null,"id":"9c33587c","metadata":{"id":"9c33587c"},"outputs":[],"source":["from confluent_kafka import Consumer\n","\n","conf = {'bootstrap.servers': \"localhost:8080\",\n","        'group.id': \"foo\",\n","        'auto.offset.reset': 'smallest',\n","        'session.timeout.ms' : 10000}\n","\n","\n","consumer = Consumer(conf) #creating consumer with my configuration"]},{"cell_type":"markdown","id":"GhDgzpMCEcAh","metadata":{"id":"GhDgzpMCEcAh"},"source":["## Processing function for incoming tweets"]},{"cell_type":"code","execution_count":null,"id":"873a7fd4","metadata":{"id":"873a7fd4"},"outputs":[],"source":["def remove_HTML(text):\n","    \"\"\"\n","    Inputs a string and outputs a string free of any HTML tags\n","    \"\"\"\n","    tag = re.compile(r'<.*?>')\n","    \n","    return tag.sub(r'',text)\n","\n","def remove_URL(text):\n","    \"\"\"\n","    Inputs a string and outputs a string free of any URLs\n","    \"\"\"\n","    url = re.compile(r'https?://\\S+|www\\.\\S+')\n","    \n","    return url.sub(r'',text)\n","\n","def remove_emojis(text):\n","    \"\"\"\n","    Inputs a string and outputs a string free of any emojis\n","    \"\"\"\n","    emoji = re.compile(\"[\"\n","        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n","        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n","        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n","        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n","        u\"\\U00002702-\\U000027B0\"\n","        u\"\\U000024C2-\\U0001F251\"\n","    \"]+\", flags=re.UNICODE)\n","    \n","    return emoji.sub(r'',text)\n","\n","def remove_punctuations(text):\n","    \"\"\"\n","    Inputs a string and outputs a string free of any punctuations\n","    \"\"\"\n","    punct = re.compile(r'[^\\w\\s]')\n","    \n","    return punct.sub(r'',text)"]},{"cell_type":"code","execution_count":null,"id":"bb50008a","metadata":{"id":"bb50008a"},"outputs":[],"source":["# set of all stopwords\n","stop = set(stopwords.words('english'))\n","stop.remove('not') # exclude not\n","\n","def remove_stop_words(text):\n","    \"\"\"\n","    inputs a text string and outputs a string without any stopwords\n","    \"\"\"\n","    sentence = [] # list without any stopwords\n","    for word in text.split():\n","        if word not in stop:\n","            sentence.append(word)\n","            \n","    return \" \".join(sentence)"]},{"cell_type":"code","execution_count":null,"id":"a6714134","metadata":{"id":"a6714134"},"outputs":[],"source":["def clean_text(text):\n","    \"\"\"\n","    inputs a string:\n","    -------------------------------------\n","    outputs a string free from \n","    1) html-tags\n","    2) urls\n","    3) punctuations\n","    4) stopwords\n","    \"\"\"\n","    text = remove_HTML(text)\n","    text = remove_URL(text)\n","    text = remove_punctuations(text)\n","    text = remove_stop_words(text)\n","    \n","    return text"]},{"cell_type":"markdown","id":"Ju5ru5TbExpq","metadata":{"id":"Ju5ru5TbExpq"},"source":["## Prepration for model"]},{"cell_type":"code","execution_count":null,"id":"3ccf56ae","metadata":{"id":"3ccf56ae"},"outputs":[],"source":["# Creating the pipeline for feature extraction\n","path =\"/home/model2\"\n","newLR = LogisticRegressionModel.load(path)\n","\n","# tokenizing the data\n","tokenizer = Tokenizer(inputCol=\"tweet\", outputCol=\"words\")\n","\n","# Creating an instance of the TF-IDF\n","hashtf = HashingTF(numFeatures=2**16, inputCol=\"words\", outputCol='tf')\n","idf = IDF(inputCol='tf', outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n","\n","# the complete pipeline: sequence of various stages\n","pipeline = Pipeline(stages=[tokenizer, hashtf, idf])"]},{"cell_type":"code","execution_count":null,"id":"f73b6149","metadata":{"id":"f73b6149"},"outputs":[],"source":["sqlContext = SQLContext(sc)\n","file_path = '/home/cleaned_train.csv'\n","df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load(file_path)\n","(train_set, val_set, test_set) = df.randomSplit([0.98, 0.01, 0.01], seed = 2000)\n","\n","pipelineFit = pipeline.fit(train_set)\n","train_df = pipelineFit.transform(train_set)"]},{"cell_type":"code","execution_count":null,"id":"78bb0fe0","metadata":{"id":"78bb0fe0"},"outputs":[],"source":["def model_predict(test_tweet_):\n","    features = pipelineFit.transform(test_tweet_)\n","    preds = newLR.transform(features)\n","    return preds"]},{"cell_type":"markdown","id":"OicyiL-GE09T","metadata":{"id":"OicyiL-GE09T"},"source":["## Consumer Loop"]},{"cell_type":"markdown","id":"p1zCGGHoE-NA","metadata":{"id":"p1zCGGHoE-NA"},"source":["The Loop:\n","\n","1.   The consumer recieves the tweets and pulls the text from them. \n","2.   The text gets cleaned using the proccessing functions and return clean text.\n","3. Using **VADER lexicon library** - pull the compound score on the given tweet and classify it to be POSITIVE or NEGATIVE. we ignored the NEUTRAL label because we want to extract the emotions from the text. see the cell below for more information on VADER library.\n","4. Model prediction - get the model prediciton to the given tweet :\n","    1.   1 - POSITIVE\n","    2.   0 - NEGATIVE\n","5. If the model prediction and the VADER classification are correlate, then we classify them to the matching label. if they are not correlated, then we decide the tweet label is unspecified. if the VADER classification is NEUTRAL, the label will be what the model predicted. \n","6. Positive tweet ratio calculation - we want what is the precenge of the positive tweets of all the tweets recieved by the consumer (expect the unspecified tweets). \n","\n","\n","\n","\n"]},{"cell_type":"markdown","id":"CQX39gzeHimH","metadata":{"id":"CQX39gzeHimH"},"source":["### VADER \n","VADER is a lexicon and a rule-based sentiment analysis tool for social media text. The lexicon has been built manually, by aggregating ratings coming from 10 human annotators.\n","Its precision should be higher than the resources created automatically. Moreover, being specifically tuned for social media, it also covers emojis and abbreviations (e.g., “lmao”, “lol”) that other dictionaries normally don’t. \n","\n","The compound score is computed by summing the valence scores of each word in the lexicon, adjusted according to the rules, and then normalized to be between -1 (most extreme negative) and +1 (most extreme positive). This is the most useful metric if you we a single unidimensional measure of sentiment for a given sentence.\n","\n","It is also useful for researchers who would like to set standardized thresholds for classifying sentences as either positive, neutral, or negative. Typical threshold values are:\n","\n","1.   positive sentiment: compound score >= 0.05\n","2.   neutral sentiment: (compound score > -0.05) and (compound score < 0.05)\n","3.   negative sentiment: compound score <= -0.05\n","\n","The compound score is the one most commonly used for sentiment analysis by most researchers, including the authors.\n","\n","[VADER](https://github.com/cjhutto/vaderSentiment)"]},{"cell_type":"code","execution_count":null,"id":"79e82787","metadata":{"id":"79e82787"},"outputs":[],"source":["running = True\n","analyzer = SentimentIntensityAnalyzer()\n","posRatio=0\n","\n","def basic_consume_loop(consumer, topics):\n","    try:\n","        posTweetSum=0 \n","        counter=1 #Tweets count\n","        unspecifiedCounter = 0\n","        consumer.subscribe(topics) #consumer subscribe to kafka topic\n","        print(\"start\")#debug\n","        while running:\n","            msg = consumer.poll(timeout=2.0) #poll the msg from kafka\n","            if msg is None: break\n","            if msg.error():\n","                if msg.error().code() == KafkaError._PARTITION_EOF:\n","                    # End of partition event\n","                    sys.stderr.write('%% %s [%d] reached end at offset %d\\n' %\n","                                     (msg.topic(), msg.partition(), msg.offset()))\n","                elif msg.error():\n","                    raise KafkaException(msg.error())\n","            else:\n","                print(20*'=') #debuging  \n","                print('Tweet Number : ', counter)\n","                tweet  = msg.value().decode('utf-8').split(\" \") #convert msg to string, and make it list that\n","             \n","                strTweet = msg.value().decode('utf-8')\n","                cleanTweet = clean_text(strTweet) \n","                vs = analyzer.polarity_scores(cleanTweet) #pull compund score fron VADER\n","                print(f\"Clean Tweet :  {cleanTweet}\")\n","                \n","                test_tweet = {'tweet':[cleanTweet]} \n","                test_tweet_ = pd.DataFrame(test_tweet)\n","                test_tweet_ = sqlContext.createDataFrame(test_tweet_)\n","                pred = model_predict(test_tweet_) #Model Prediction\n","                print('model prediction : ', pred.first()['prediction'])\n","             \n","                counter=counter+1 \n","                \n","                ifPos = 1 if vs['compound'] >= 0.05 else 0 #Classify the tweet based on VADER\n","                ifNeutral = 1 if (vs['compound'] > -0.05 and vs['compound'] < 0.05) else 0\n","                ifNeg = 1 if vs['compound'] <= -0.05 else 0\n","\n","                if pred.first()[\"prediction\"] == 1.0 and ifPos == 1:\n","                    posTweetSum=posTweetSum+1\n","                    print(\"Tweet Sentimental = POSITIVE\")\n","                    \n","                elif pred.first()[\"prediction\"] == 0.0 and ifNeg == 1:\n","                    print(\"Tweet Sentimental = NEGATIVE\")\n","                    \n","                elif ifNeutral == 1:\n","                    if pred.first()[\"prediction\"] == 1.0:\n","                         posTweetSum=posTweetSum+1\n","                         print(\"Tweet Sentimental = POSITIVE\")\n","                    else:\n","                         print(\"Tweet Sentimental = NEGATIVE\") \n","                \n","                elif (pred.first()[\"prediction\"] == 1.0 and ifNeg == 1) or (pred.first()[\"prediction\"] == 0.0 and ifNeg != 1) :\n","                    unspecifiedCounter = unspecifiedCounter + 1\n","                    print(\"Tweet Sentimental = UNSPECIFIED\")\n","                     \n","                if (counter - unspecifiedCounter - 1) > 0:\n","                    posRatio = (posTweetSum / (counter - unspecifiedCounter - 1)) \n","                else:\n","                    posRatio = 0\n","                    \n","                print(f\"Positive Ratio  = {posRatio:.2f}\")\n","                print(20*'=') #debuging     \n","                \n","                \n","                    \n","    finally:\n","        # Close down consumer to commit final offsets.\n","        consumer.close()\n","    return posRatio\n","    \n","def shutdown():\n","    running = False"]},{"cell_type":"code","execution_count":null,"id":"8783958d","metadata":{"id":"8783958d","outputId":"0750c5f2-ca0b-40ea-d2a2-d2eda21025a0"},"outputs":[],"source":["posRatio = basic_consume_loop(consumer, ['twitter'])"]},{"cell_type":"markdown","id":"qEIg1hIsK8ZP","metadata":{"id":"qEIg1hIsK8ZP"},"source":["## Ratio decision - \n","if we have more than 50% positive tweets, then the tweets on that given time and subject are mostly positive. The same goes for the negative and neutral tweets. "]},{"cell_type":"code","execution_count":null,"id":"1d74fd21","metadata":{"id":"1d74fd21"},"outputs":[],"source":["if posRatio > 0.5:\n","    print(\"Based on the given subject , most of the tweets defined as positive\")\n","\n","elif posRatio < 0.5:\n","    print(\"Based on the given subject , most of the tweets defined as negative\")\n","else: \n","    print(\"Based on the given subject , most of the tweets defined as neutral\")"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"twitterConsumer.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}
